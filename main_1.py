# main.py
# ======================================================
# ğŸš€ Math Grading API (FastAPI + SymPy + LLM)
#  - POST /grade_equation
# ======================================================

from typing import List, Optional, Dict, Any
from dataclasses import dataclass
import os
import json
import re

from fastapi import FastAPI
from pydantic import BaseModel

import sympy as sp
from sympy.parsing.latex import parse_latex

# Ù„Ùˆ Ø³ØªØ³ØªØ®Ø¯Ù… OpenAI Ù…Ø«Ù„Ø§:
# pip install openai
# from openai import OpenAI
# client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ======================================================
# 1) SymPy-based MathChecker
# ======================================================

def clean_latex(s: str) -> str:
    s = s.strip()
    s = s.replace("$$", "").replace("$", "")
    s = s.replace("\\[", "").replace("\\]", "")
    s = re.sub(r"\s+", " ", s)
    return s.strip()


def looks_like_latex(s: str) -> bool:
    return "\\" in s or "_{" in s or "^{" in s


def normalize_plain_expr(s: str) -> str:
    s = s.strip()

    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø³Ø³
    s = s.replace("^", "**")
    s = s.replace("Â²", "**2").replace("Â³", "**3")

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    s = re.sub(r"\s+", "", s)

    # âœ… Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¶Ø±Ø¨ Ø§Ù„Ø¶Ù…Ù†ÙŠ:
    # 12x -> 12*x
    s = re.sub(r"(\d)([a-zA-Z])", r"\1*\2", s)

    # x2 -> x*2 (Ù†Ø§Ø¯Ø±Ø§Ù‹ Ù„ÙƒÙ†Ù‡Ø§ ØªØ­ØµÙ„)
    s = re.sub(r"([a-zA-Z])(\d)", r"\1*\2", s)

    # )x -> )*x
    s = re.sub(r"\)([a-zA-Z])", r")*\1", s)

    # x( -> x*( 
    s = re.sub(r"([a-zA-Z])\(", r"\1*(", s)

    return s


def parse_expression(expr_str: str) -> sp.Expr:
    expr_str = expr_str.strip()
    if not expr_str:
        raise ValueError("Empty expression")

    # Ø­Ø§ÙˆÙ„ LaTeX Ø£ÙˆÙ„Ø§Ù‹
    if looks_like_latex(expr_str):
        try:
            expr = parse_latex(clean_latex(expr_str))
            return sp.simplify(expr)
        except Exception:
            pass

    # Ø«Ù… ØµÙŠØºØ© Ø¨Ø³ÙŠØ·Ø©
    expr_str2 = normalize_plain_expr(expr_str)
    expr = sp.sympify(expr_str2)
    return sp.simplify(expr)


def parse_equation(eq_str: str) -> sp.Expr:
    eq_str = eq_str.strip()
    if "=" in eq_str:
        parts = eq_str.split("=")
        lhs_str = "=".join(parts[:-1])
        rhs_str = parts[-1]
    else:
        lhs_str = eq_str
        rhs_str = "0"

    lhs = parse_expression(lhs_str)
    rhs = parse_expression(rhs_str)
    expr = sp.simplify(lhs - rhs)
    return sp.expand(expr)


def compare_terms(teacher_expr: sp.Expr, student_expr: sp.Expr) -> Dict[str, Any]:
    t_terms = sp.Add.make_args(sp.expand(teacher_expr))
    s_terms = sp.Add.make_args(sp.expand(student_expr))

    def term_map(terms):
        m = {}
        for t in terms:
            c, rest = t.as_coeff_Mul()
            m.setdefault(rest, 0)
            m[rest] += c
        return m

    t_map = term_map(t_terms)
    s_map = term_map(s_terms)

    missing = []
    extra = []
    coeff_diff = []

    for rest, t_coeff in t_map.items():
        s_coeff = s_map.get(rest, 0)
        if sp.simplify(s_coeff) == 0:
            missing.append(str(t_coeff * rest))
        elif sp.simplify(t_coeff - s_coeff) != 0:
            coeff_diff.append(
                {
                    "term": str(rest),
                    "teacher_coeff": float(t_coeff),
                    "student_coeff": float(s_coeff),
                }
            )

    for rest, s_coeff in s_map.items():
        t_coeff = t_map.get(rest, 0)
        if sp.simplify(t_coeff) == 0:
            extra.append(str(s_coeff * rest))

    return {
        "missing_terms": missing,
        "extra_terms": extra,
        "coeff_mismatch": coeff_diff,
    }


@dataclass
class CheckResult:
    is_correct: bool
    teacher_expr: sp.Expr
    student_expr: sp.Expr
    diff_expr: sp.Expr
    error_type: Optional[str]
    details: Dict[str, Any]


class MathChecker:
    def check_equation(self, teacher_str: str, student_str: str) -> CheckResult:
        t_expr = parse_equation(teacher_str)
        s_expr = parse_equation(student_str)
        diff = sp.simplify(t_expr - s_expr)

        if sp.simplify(diff) == 0:
            return CheckResult(
                is_correct=True,
                teacher_expr=t_expr,
                student_expr=s_expr,
                diff_expr=diff,
                error_type=None,
                details={},
            )

        term_analysis = compare_terms(t_expr, s_expr)

        error_type = "unknown"
        if term_analysis["missing_terms"] and not term_analysis["extra_terms"]:
            error_type = "missing_terms"
        elif term_analysis["extra_terms"] and not term_analysis["missing_terms"]:
            error_type = "extra_terms"
        elif term_analysis["coeff_mismatch"]:
            error_type = "coefficient_mismatch"

        return CheckResult(
            is_correct=False,
            teacher_expr=t_expr,
            student_expr=s_expr,
            diff_expr=diff,
            error_type=error_type,
            details=term_analysis,
        )


checker = MathChecker()

# ======================================================
# 2) LLM Feedback Prompt Builder
# ======================================================

def build_llm_feedback_prompt(
    teacher_eq: str,
    student_eq: str,
    sympy_result_dict: dict,
    question_text: str = "",
    teacher_steps: Optional[List[str]] = None,
    student_steps: Optional[List[str]] = None,
) -> str:
    teacher_steps = teacher_steps or []
    student_steps = student_steps or []

    sympy_json = json.dumps(sympy_result_dict, ensure_ascii=False, indent=2)

    prompt = f"""
Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø®Ø¨ÙŠØ± Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠØ©/Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©.
Ù…Ù‡Ù…ØªÙƒ:
- Ù…Ù‚Ø§Ø±Ù†Ø© Ø­Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…Ø¹ Ø§Ù„Ø­Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠ.
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ù…Ø²ÙŠ (SymPy) ÙƒÙ…Ø¹Ù„ÙˆÙ…Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙ‚Ø·.
- Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·.

### Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ (Ø§Ù„Ø¹Ø±Ø¨ÙŠ):
{question_text}

### Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© (Ù…Ù† Ø§Ù„Ù…Ø¯Ø±Ù‘Ø³):
{teacher_eq}

### Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø·Ø§Ù„Ø¨:
{student_eq}

### Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø­Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠ (Ø¥Ù† ÙˆØ¬Ø¯Øª):
{json.dumps(teacher_steps, ensure_ascii=False, indent=2)}

### Ø®Ø·ÙˆØ§Øª Ø­Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ (Ø¥Ù† ÙˆØ¬Ø¯Øª):
{json.dumps(student_steps, ensure_ascii=False, indent=2)}

### Ù†ØªÙŠØ¬Ø© SymPy:
{sympy_json}

Ø£Ø±Ø¬ÙˆÙƒ Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·ØŒ Ø¨Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:

{{
  "is_correct": <true or false>,
  "score": <number between 0 and 1>,
  "error_type": "<fully_correct | small_algebra_mistake | concept_mistake | incomplete_solution | off_topic>",
  "short_verdict_ar": "<Ø¬Ù…Ù„Ø© Ù‚ØµÙŠØ±Ø© Ø¹Ù† ØµØ­Ø© Ø§Ù„Ø­Ù„>",
  "main_error_ar": "<Ø´Ø±Ø­ Ø¨Ø³ÙŠØ· Ø¹Ù† Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ>",
  "step_feedback": [
    {{
      "step_index": 0,
      "is_correct": true,
      "comment_ar": "<ØªØ¹Ù„ÙŠÙ‚ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©>"
    }}
  ],
  "suggested_next_question_ar": "<Ø³Ø¤Ø§Ù„ ØªØ¯Ø±ÙŠØ¨ÙŠ Ø¬Ø¯ÙŠØ¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©>"
}}
"""
    return prompt


def call_llm(prompt: str) -> dict:
    """
    Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ­ØªØ§Ø¬ Ø£Ù† ØªØ±Ø¨Ø·Ù‡Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§ Ø¨Ù€ LLM Ø§Ù„Ø°ÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡.
    Ù‡Ù†Ø§ Ø£Ø¶Ø¹ Ø´ÙƒÙ„Ù‹Ø§ Ø¹Ø§Ù…Ù‘Ù‹Ø§ØŒ Ø¹Ø¯Ù‘Ù„ Ø­Ø³Ø¨ Ù…Ø²ÙˆÙ‘Ø¯Ùƒ (OpenAI / ØºÙŠØ±Ù‡).

    Ø§Ù„Ø¢Ù†: Ø£Ø¶Ø¹ ØªÙ†ÙÙŠØ° Ø¨Ø³ÙŠØ· "mock" Ø­ØªÙ‰ Ù„Ø§ ÙŠÙƒØ³Ø± Ø§Ù„ÙƒÙˆØ¯ Ù„Ùˆ Ù…Ø§ Ø¹Ù†Ø¯Ùƒ LLM Ø¬Ø§Ù‡Ø².
    """

    # --- Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ OpenAIØŒ Ø§Ø³ØªØ¹Ù…Ù„ Ø´ÙŠØ¡ Ø´Ø¨ÙŠÙ‡ Ø¨Ù‡Ø°Ø§:
    # response = client.chat.completions.create(
    #     model="gpt-4o-mini",
    #     messages=[
    #         {"role": "system", "content": "Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø®Ø¨ÙŠØ± ÙˆØ¯Ù‚ÙŠÙ‚."},
    #         {"role": "user", "content": prompt},
    #     ],
    #     temperature=0.2,
    # )
    # content = response.choices[0].message.content

    # ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ø³Ø®Ø©ØŒ Ù†Ø±Ø¬Ù‘Ø¹ Ù†Ù…ÙˆØ°Ø¬Ù‹Ø§ Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§ (stub) Ø­ØªÙ‰ ØªØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¨Ø· Ø£ÙˆÙ„Ø§Ù‹:
    content = json.dumps(
        {
            "is_correct": False,
            "score": 0.5,
            "error_type": "small_algebra_mistake",
            "short_verdict_ar": "Ø­Ù„Ù‘Ùƒ Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„ØµØ­ÙŠØ­ Ù„ÙƒÙ† ÙÙŠÙ‡ Ø®Ø·Ø£ Ø¬Ø¨Ø±ÙŠ Ø¨Ø³ÙŠØ·.",
            "main_error_ar": "ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ùƒ Ø£Ø®Ø·Ø£Øª ÙÙŠ Ø¥Ø´Ø§Ø±Ø© Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø£Ùˆ ÙÙŠ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ØªØ±Ø¨ÙŠØ¹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ³.",
            "step_feedback": [],
            "suggested_next_question_ar": "Ø­Ø§ÙˆÙ„ Ø­Ù„ Ø§Ù„Ù…Ø³Ø£Ù„Ø©: Ø¬Ø¯ Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù‚Ø·Ø¹ Ø§Ù„Ù…ÙƒØ§ÙØ¦ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¨Ø¤Ø±ØªÙ‡ (4,0) ÙˆØ®Ø·Ù‡ Ø§Ù„Ø¯Ù„ÙŠÙ„ x = -4.",
        },
        ensure_ascii=False,
    )

    try:
        return json.loads(content)
    except json.JSONDecodeError:
        # fallback ÙÙŠ Ø­Ø§Ù„ Ø­ØµÙ„ Ø´ÙŠØ¡ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹
        return {
            "is_correct": False,
            "score": 0.0,
            "error_type": "unknown",
            "short_verdict_ar": "ØªØ¹Ø°Ø± ØªØ­Ù„ÙŠÙ„ Ø±Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.",
            "main_error_ar": "",
            "step_feedback": [],
            "suggested_next_question_ar": "",
        }


def llm_feedback(
    teacher_eq: str,
    student_eq: str,
    sympy_result: CheckResult,
    question_text: str = "",
    teacher_steps: Optional[List[str]] = None,
    student_steps: Optional[List[str]] = None,
) -> dict:
    sympy_result_dict = {
        "is_correct": sympy_result.is_correct,
        "error_type": sympy_result.error_type,
        "details": sympy_result.details,
        "teacher_expr_str": str(sympy_result.teacher_expr),
        "student_expr_str": str(sympy_result.student_expr),
        "diff_expr_str": str(sympy_result.diff_expr),
    }

    prompt = build_llm_feedback_prompt(
        teacher_eq=teacher_eq,
        student_eq=student_eq,
        sympy_result_dict=sympy_result_dict,
        question_text=question_text,
        teacher_steps=teacher_steps,
        student_steps=student_steps,
    )

    feedback = call_llm(prompt)
    return feedback


# ======================================================
# 3) FastAPI Models
# ======================================================

class GradeRequest(BaseModel):
    # Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙƒÙ…Ø§ Ø§Ø³ØªØ®Ø±Ø¬ØªÙ‡ Ù…Ù† OCR
    question_text: Optional[str] = ""
    # Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø±Ø³ (LaTeX Ø£Ùˆ Ù†Øµ)
    teacher_equation: str
    # Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ (LaTeX Ø£Ùˆ Ù†Øµ)
    student_equation: str
    # Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¯Ø±Ø³ Ø¨ØµÙŠØºØ© LaTeX Ø£Ùˆ Ù†ØµÙˆØµ
    teacher_steps: Optional[List[str]] = None
    # Ø§Ø®ØªÙŠØ§Ø±ÙŠ: Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø±Ø¬Ù‡Ø§
    student_steps: Optional[List[str]] = None


class SympyResultResponse(BaseModel):
    is_correct: bool
    error_type: Optional[str]
    details: Dict[str, Any]
    teacher_expr_str: str
    student_expr_str: str
    diff_expr_str: str


class StepFeedback(BaseModel):
    step_index: int
    is_correct: bool
    comment_ar: str


class LLMFeedbackResponse(BaseModel):
    is_correct: bool
    score: float
    error_type: str
    short_verdict_ar: str
    main_error_ar: str
    step_feedback: List[StepFeedback] = []
    suggested_next_question_ar: str


class GradeResponse(BaseModel):
    sympy_result: SympyResultResponse
    llm_feedback: LLMFeedbackResponse


class SolutionStep(BaseModel):
    index: int
    equation_latex: str

class TeacherSolution(BaseModel):
    steps: List[SolutionStep]

class OCRQuestion(BaseModel):
    question_text: str
    equation_item_ids: List[int]
    solution: TeacherSolution

class StudentAnswer(BaseModel):
    final_equation: str
    steps: Optional[List[SolutionStep]] = []

class FullGradeRequest(BaseModel):
    question: OCRQuestion
    student_answers: StudentAnswer


class StepGrade(BaseModel):
    step_index: int
    sympy_correct: bool
    sympy_error_type: Optional[str]
    llm_feedback: LLMFeedbackResponse


class FullGradeResponse(BaseModel):
    final_score: float
    final_verdict_ar: str
    steps_result: List[StepGrade]


# ======================================================
# 4) FastAPI app + endpoints
# ======================================================

app = FastAPI(title="Math Grading API", version="1.0.0")


@app.get("/health")
def health_check():
    return {"status": "ok"}


@app.post("/grade_equation", response_model=GradeResponse)
def grade_equation(req: GradeRequest):

    # 1) SymPy check
    sym_res = checker.check_equation(req.teacher_equation, req.student_equation)

    sympy_payload = SympyResultResponse(
        is_correct=sym_res.is_correct,
        error_type=sym_res.error_type,
        details=sym_res.details,
        teacher_expr_str=str(sym_res.teacher_expr),
        student_expr_str=str(sym_res.student_expr),
        diff_expr_str=str(sym_res.diff_expr),
    )

    # 2) LLM feedback
    fb = llm_feedback(
        teacher_eq=req.teacher_equation,
        student_eq=req.student_equation,
        sympy_result=sym_res,
        question_text=req.question_text or "",
        teacher_steps=req.teacher_steps,
        student_steps=req.student_steps,
    )

    step_fb_objects = [
        StepFeedback(
            step_index=sf.get("step_index", 0),
            is_correct=sf.get("is_correct", False),
            comment_ar=sf.get("comment_ar", ""),
        )
        for sf in fb.get("step_feedback", [])
    ]

    llm_fb = LLMFeedbackResponse(
        is_correct=fb.get("is_correct", sym_res.is_correct),
        score=float(fb.get("score", 1.0 if sym_res.is_correct else 0.0)),
        error_type=fb.get("error_type", sym_res.error_type or "unknown"),
        short_verdict_ar=fb.get(
            "short_verdict_ar",
            "Ø¥Ø¬Ø§Ø¨ØªÙƒ ØµØ­ÙŠØ­Ø©." if sym_res.is_correct else "Ø¥Ø¬Ø§Ø¨ØªÙƒ ØºÙŠØ± ØµØ­ÙŠØ­Ø©.",
        ),
        main_error_ar=fb.get("main_error_ar", ""),
        step_feedback=step_fb_objects,
        suggested_next_question_ar=fb.get("suggested_next_question_ar", ""),
    )

    return GradeResponse(sympy_result=sympy_payload, llm_feedback=llm_fb)


@app.post("/grade_full_question", response_model=FullGradeResponse)
def grade_full_question(req: FullGradeRequest):

    teacher_steps = req.question.solution.steps
    student_steps = req.student_answers.steps or []

    steps_result = []
    total_score = 0.0
    counted_steps = 0

    # Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„
    question_text = req.question.question_text

    # === ØªØµØ­ÙŠØ­ ÙƒÙ„ Ø®Ø·ÙˆØ© ===
    for t_step in teacher_steps:

        # Ù†Ø­Ø§ÙˆÙ„ Ù†Ø·Ø§Ø¨Ù‚ Ø®Ø·ÙˆØ© Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨Ù†ÙØ³ index
        s_step = next(
            (s for s in student_steps if s.index == t_step.index),
            None
        )

        if s_step is None:
            # Ø§Ù„Ø·Ø§Ù„Ø¨ Ù„Ù… ÙŠÙƒØªØ¨ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©
            sym_res = checker.check_equation(
                t_step.equation_latex, "0"
            )

            fb = llm_feedback(
                teacher_eq=t_step.equation_latex,
                student_eq="",
                sympy_result=sym_res,
                question_text=question_text
            )

            step_score = fb.get("score", 0.0)

        else:
            sym_res = checker.check_equation(
                t_step.equation_latex,
                s_step.equation_latex
            )

            fb = llm_feedback(
                teacher_eq=t_step.equation_latex,
                student_eq=s_step.equation_latex,
                sympy_result=sym_res,
                question_text=question_text
            )

            step_score = fb.get("score", 0.0)

        total_score += step_score
        counted_steps += 1

        step_feedback_obj = StepGrade(
            step_index=t_step.index,
            sympy_correct=sym_res.is_correct,
            sympy_error_type=sym_res.error_type,
            llm_feedback=LLMFeedbackResponse(
                is_correct=fb.get("is_correct", False),
                score=float(fb.get("score", 0.0)),
                error_type=fb.get("error_type", "unknown"),
                short_verdict_ar=fb.get("short_verdict_ar", ""),
                main_error_ar=fb.get("main_error_ar", ""),
                step_feedback=[
                    StepFeedback(
                        step_index=x.get("step_index", 0),
                        is_correct=x.get("is_correct", False),
                        comment_ar=x.get("comment_ar", "")
                    )
                    for x in fb.get("step_feedback", [])
                ],
                suggested_next_question_ar=fb.get("suggested_next_question_ar", "")
            )
        )

        steps_result.append(step_feedback_obj)

    # === Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ===
    final_score = total_score / max(1, counted_steps)

    if final_score > 0.85:
        verdict = "Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù…ØªØ§Ø²Ø© âœ…"
    elif final_score > 0.6:
        verdict = "Ø¥Ø¬Ø§Ø¨Ø© Ø¬ÙŠØ¯Ø© Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ âš ï¸"
    elif final_score > 0.3:
        verdict = "Ø¥Ø¬Ø§Ø¨Ø© Ø¶Ø¹ÙŠÙØ© ÙˆØªØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© âŒ"
    else:
        verdict = "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ØºÙŠØ± ØµØ­ÙŠØ­Ø© ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§ âŒ"

    return FullGradeResponse(
        final_score=round(final_score, 2),
        final_verdict_ar=verdict,
        steps_result=steps_result
    )
